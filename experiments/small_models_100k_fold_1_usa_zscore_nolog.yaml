models:
  # EALSTM model (100,954 parameters)
  ealstm_100k_fold_1_usa_zscore_nolog: configs/models/ealstm_100k_fold_1_usa_zscore_nolog.yaml

  # Mamba model (99,405 parameters)
  mamba_100k_fold_1_usa_zscore_nolog: configs/models/mamba_100k_fold_1_usa_zscore_nolog.yaml

trainer:
  mode: evaluation
  max_epochs: 150
  early_stopping_patience: 15
  accumulate_grad_batches: 1
  check_val_every_n_epoch: 1
  gradient_clip_val: 1.0
